a0sqr<- 4
alpha0<- 5
beta0<- 1
t0=1/a0sqr
t<-t0#assume equal t0 at first
#posterior estimate for u
thismean<- (n*xbar*t+u0*t0)/(n*t+t0)
thisvariance <- 1/(n*t+t0)
u_estimates<-rnorm(1000,thismean,thisvariance)
u<-mean(u_estimates)
#posterior estimate for t
S <- sum((x_values-u_estimate)^2)
this_shape<-alpha0+n/2
this_scale<-beta0+S/2
t_estimates<-rgamma(1000,this_shape,this_scale)
t<-mean(t_estimates)
#repeat1000times
u_values<-c()
t_values<-c()
for (i in 1:500) {
#estimate u
thismean<- ((n*xbar*t)+(u0*t0))/((n*t)+t0)
thisvariance <- 1/(n*t+t0)
u_estimates<-rnorm(1000,thismean,thisvariance)
u<-mean(u_estimates)
#estimate t
S <- sum((x_values-u)^2)
this_shape<-alpha0+(n/2)
this_scale<-beta0+(S/2)
t_estimates<-rgamma(1000,shape=this_shape,scale=this_scale)
t<-mean(t_estimates)
u_values[i]=u
t_values[i]=t
}
sigmasquared_values = 1/t_values
x_axis = c(1:500)
plot(x_axis,u_values,ylim=c(9.5,10))
plot(1/t_values)
plot(sigmasquared_values,ylim=c(6,18))
#finalestimates
mean(u_values)
mean(sigmasquared_values)
set.seed(123)
x_values <- c(12.8, 10.5, 13.2, 13.0, 7.0, 11.0, 13.4, 13.2, 9.5, 11.0, 10.9, 4.6, 5.8, 3.2, 9.8, 0.2, 11.2,
7.2, 14.7, 5.9, 9.7, 17.6, 8.5, 6.8, 7.2, 12.2, 16.7, 10.4, 14.2, 5.7)
xbar<- mean(x_values)
n<-length(x_values)
u0<- 8
a0sqr<- 4
alpha0<- 5
beta0<- 1
t0=1/a0sqr
t<-t0#assume equal t0 at first
#posterior estimate for u
thismean<- (n*xbar*t+u0*t0)/(n*t+t0)
thisvariance <- 1/(n*t+t0)
u_estimates<-rnorm(1000,thismean,thisvariance)
u<-mean(u_estimates)
#posterior estimate for t
S <- sum((x_values-u_estimate)^2)
this_shape<-alpha0+n/2
this_scale<-beta0+S/2
t_estimates<-rgamma(1000,shape=this_shape,scale=this_scale)
t<-mean(t_estimates)
#repeat1000times
u_values<-c()
t_values<-c()
for (i in 1:500) {
#estimate u
thismean<- ((n*xbar*t)+(u0*t0))/((n*t)+t0)
thisvariance <- 1/(n*t+t0)
u_estimates<-rnorm(1000,thismean,thisvariance)
u<-mean(u_estimates)
#estimate t
S <- sum((x_values-u)^2)
this_shape<-alpha0+(n/2)
this_scale<-beta0+(S/2)
t_estimates<-rgamma(1000,shape=this_shape,scale=this_scale)
t<-mean(t_estimates)
u_values[i]=u
t_values[i]=t
}
sigmasquared_values = 1/t_values
x_axis = c(1:500)
plot(x_axis,u_values,ylim=c(9.5,10))
plot(1/t_values)
plot(sigmasquared_values,ylim=c(6,18))
#finalestimates
mean(u_values)
mean(sigmasquared_values)
plot(sigmasquared_values,ylim=c(6,18))
plot(sigmasquared_values,ylim=c(0,1))
plot(sigmasquared_values,ylim=c(0,0.2))
plot(sigmasquared_values,ylim=c(0,0.1))
plot(sigmasquared_values,ylim=c(0,0.001))
plot(x_axis,u_values)
,ylim=c(9.5,10)
plot(x_axis,u_values,ylim=c(9.5,10))
plot(x_axis,u_values,ylim=c(9.7,10))
plot(x_axis,u_values,ylim=c(9.8,10))
plot(x_axis,u_values,ylim=c(9.87,10))
plot(x_axis,u_values,ylim=c(9.87,9.92))
u_values
plot(x_axis,u_values,ylim=c(9.9,9.91))
plot(x_axis,u_values,ylim=c(9.902,9.904))
plot(x_axis,u_values,ylim=c(9.903,9.9034))
plot(x_axis,u_values,ylim=c(9.9034,9.9034))
plot(x_axis,u_values,ylim=c(9.903,9.9034))
plot(x_axis,u_values,ylim=c(9.9032,9.9034))
plot(x_axis,u_values,ylim=c(9.9033,9.9034))
plot(x_axis,u_values,ylim=c(9.9033,9.90334))
plot(x_axis,u_values,ylim=c(9.90332,9.90334))
plot(x_axis,u_values,ylim=c(9.903325,9.90334))
plot(x_axis,u_values,ylim=c(9.903325,9.903335))
plot(sigmasquared_values,ylim=c(0,0.001))
plot(sigmasquared_values,ylim=c(0,0.00001))
plot(sigmasquared_values,ylim=c(0,0.0001))
plot(sigmasquared_values,ylim=c(0,0.001))
plot(sigmasquared_values,ylim=c(0,0.0009))
plot(sigmasquared_values,ylim=c(0,0.0005))
plot(sigmasquared_values,ylim=c(0,0.0003))
plot(sigmasquared_values,ylim=c(00.000001,0.0003))
plot(sigmasquared_values,ylim=c(00.00001,0.0003))
plot(sigmasquared_values,ylim=c(00.0001,0.0003))
plot(sigmasquared_values,ylim=c(00.0004,0.0003))
plot(sigmasquared_values,ylim=c(00.0002,0.0003))
#finalestimates
mean(u_values)
mean(sigmasquared_values)
t_estimates
sigmasquared_values
t_estimates
plot(t_estimates)
max(sigmasquared_values)
u
t
mean(u_values)
mean(sigmasquared_values)
set.seed(123)
x_values <- c(12.8, 10.5, 13.2, 13.0, 7.0, 11.0, 13.4, 13.2, 9.5, 11.0, 10.9, 4.6, 5.8, 3.2, 9.8, 0.2, 11.2,
7.2, 14.7, 5.9, 9.7, 17.6, 8.5, 6.8, 7.2, 12.2, 16.7, 10.4, 14.2, 5.7)
xbar<- mean(x_values)
n<-length(x_values)
u0<- 8
a0sqr<- 4
alpha0<- 5
beta0<- 1
t0=1/a0sqr
t<-t0#assume equal t0 at first
#posterior estimate for u
thismean<- (n*xbar*t+u0*t0)/(n*t+t0)
thisvariance <- 1/(n*t+t0)
u_estimates<-rnorm(1000,thismean,thisvariance)
u<-mean(u_estimates)
#posterior estimate for t
S <- sum((x_values-u_estimate)^2)
this_shape<-alpha0+n/2
this_scale<-beta0+S/2
t_estimates<-rgamma(1000,shape=this_shape,scale=this_scale)
t<-mean(t_estimates)
#repeat1000times
u_values<-c()
t_values<-c()
for (i in 1:500) {
#estimate u
thismean<- ((n*xbar*t)+(u0*t0))/((n*t)+t0)
thisvariance <- 1/(n*t+t0)
u_estimates<-rnorm(1000,thismean,thisvariance)
u<-mean(u_estimates)
#estimate t
S <- sum((x_values-u)^2)
this_shape<-alpha0+(n/2)
this_scale<-beta0+(S/2)
t_estimates<-rgamma(1000,shape=this_shape,scale=this_scale)
t<-mean(t_estimates)
u_values[i]=u
t_values[i]=t
}
sigmasquared_values = 1/t_values
x_axis = c(1:500)
plot(x_axis,u_values,ylim=c(9.903325,9.903335))
plot(sigmasquared_values,ylim=c(00.0002,0.0003))
#finalestimates
mean(u_values)
mean(sigmasquared_values)
devtools::install_github("connolr3/eegdatasim")
devtools::install_github("connolr3/eegdatasim",force = TRUE)
remove.packages("eegdatasim", lib="~/R/win-library/4.1")
devtools::install_github("connolr3/eegdatasim")
library(eegdatasim)
noise(200,1,250)
makinen1a()
remove.packages("eegdatasim", lib="~/R/win-library/4.1")
devtools::install_github("connolr3/eegdatasim")
devtools::install_github("connolr3/eegdatasim")
library(eegdatasim)
noise(200,1,250)
remove.packages("eegdatasim", lib="~/R/win-library/4.1")
devtools::install_github("connolr3/eegdatasim")
library(eegdatasim)
noise(200,1,250)
remove.packages("eegdatasim", lib="~/R/win-library/4.1")
devtools::install_github("connolr3/eegdatasim")
library(eegdatasim)
noise(200,1,250)
remove.packages("eegdatasim", lib="~/R/win-library/4.1")
remove.packages("eegdatasim", lib="~/R/win-library/4.1")
devtools::install_github("connolr3/eegdatasim")
library(eegdatasim)
noise(200,1,250)
remove.packages("eegdatasim", lib="~/R/win-library/4.1")
devtools::install_github("connolr3/eegdatasim")
remove.packages("eegdatasim", lib="~/R/win-library/4.1")
devtools::install_github("connolr3/eegdatasim")
devtools::install_github("connolr3/eegdatasim")
devtools::install_github("connolr3/eegdatasim")
devtools::install_github("connolr3/eegdatasim")
library(eegdatasim)
noise(200,1,250)
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")
hist( S, breaks=15, xlab="S", main="Histogram score samples")
hist( minusdS, breaks=15, xlab="-dS", main="Histogram negative deriv score samples")
hist( minusdS, breaks=15, xlab="-dS", main="Histogram negative deriv score samples")
hist( minusdS, breaks=15, xlab="-dS", main="Histogram negative deriv score samples")
hist( -1*minusdS, breaks=15, xlab="-dS", main="Histogram negative deriv score samples")
n <- 100 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
mu <- 7 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
N <- 500 # number of replications
n <- 10 # sample size
mu <- 3 # true value of mu
X <- matrix( rpois( n * N, lambda=mu ), nrow=N ) # replicate in each row
# compute realizations of the score and its negative deriv at true value of mu
S <- rowSums(X) / mu  - n
minusdS <- rowSums(X) / mu^2
hist( S, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
hist( minusdS, breaks=15, xlab="-dS", main="Histogram negative deriv score samples")
# we can overlay a vertical line on the histogram using
abline( v = 2, col="blue", lty="dotted", lwd=2)
ex_val<-mean(minusds)
ex_val<-mean(minusdS)
ex_val<-mean(minusdS)
abline(v = ex_val, col="green", lty="dotted", lwd=2)
# take mu different from the "true" value
mu.1 <- 2
S.1 <- rowSums(X) / mu.1  - n
minusdS.1 <- rowSums(X) / mu.1^2
# redraw the histograms-- what do we observe?
hist( S.1, breaks=15, xlab="S", main="Histogram score samples")#expected value is 0
#expected value is no longer 0
hist( minusdS.1, breaks=15, xlab="-dS", main="Histogram negative deriv score samples")
# true parameter values
alpha <- 2
beta <- 0.1
n <- 100 # sample size
x <- rgamma( n, shape=alpha, rate=beta )  # simulated data
negll <- function( par, xx )
{
a <- par[1]
b <- par[2]
- sum( dgamma( xx, shape=a, rate=b, log=TRUE ) ) # neg log like
}
initial <- c(1.0,0.5)
mle <- optim( initial, fn=negll, gr=NULL, xx=x, method="BFGS" )
mle$par
negll.rp <- function( par, xx )
{
a <- exp( par[1] )
b <- exp( par[2] )
- sum( dgamma( xx, shape=a, rate=b, log=TRUE ) ) # neg log like
}
initial.rp <- log(initial)
mle.rp <- optim( initial.rp, fn=negll.rp, gr=NULL, xx=x, method="BFGS" )
exp( mle.rp$par )
hist( x, freq=FALSE, xlab="x", main="Histogram of x")
# overlay fitted model
curve( dgamma(x,shape=exp(mle.rp$par[1]), rate=exp(mle.rp$par[2])), from=.001, to=90, add=T, col="blue")
initial <- c(1.0,0.5)
mle <- optim( initial, fn=negll, gr=NULL, xx=x, method="BFGS" )
mle$par#very close to true values
warnings()
exp(2)
negll.rp <- function( par, xx )
{
a <- exp( par[1] )
b <- exp( par[2] )
- sum( dgamma( xx, shape=a, rate=b, log=TRUE ) ) # neg log like
}
initial.rp <- log(initial)
mle.rp <- optim( initial.rp, fn=negll.rp, gr=NULL, xx=x, method="BFGS" )
#BFGS - quasi-newton method, bfgs stands for inventor's names
exp( mle.rp$par )
hist( x, freq=FALSE, xlab="x",bibs=20, main="Histogram of x")
hist( x, freq=FALSE, xlab="x",bins=20, main="Histogram of x")
hist( x, freq=FALSE, xlab="x", main="Histogram of x")
hist( x, freq=FALSE, xlab="x", main="Histogram of x")
hist( x, freq=FALSE,breaks = 20, xlab="x", main="Histogram of x")
hist( x, freq=FALSE,breaks = 30, xlab="x", main="Histogram of x")
# overlay fitted model
curve( dgamma(x,shape=exp(mle.rp$par[1]), rate=exp(mle.rp$par[2])), from=.001, to=90, add=T, col="blue")
hist( x, freq=FALSE,breaks = 20, xlab="x", main="Histogram of x")
# overlay fitted model
curve( dgamma(x,shape=exp(mle.rp$par[1]), rate=exp(mle.rp$par[2])), from=.001, to=90, add=T, col="blue")
hist( x, freq=FALSE,breaks = 15, xlab="x", main="Histogram of x")
# overlay fitted model
curve( dgamma(x,shape=exp(mle.rp$par[1]), rate=exp(mle.rp$par[2])), from=.001, to=90, add=T, col="blue")
n <- 1000 # sample size
x <- rgamma( n, shape=alpha, rate=beta )  # simulated data
negll <- function( par, xx )#neg log liklihood
{
a <- par[1]
b <- par[2]
- sum( dgamma( xx, shape=a, rate=b, log=TRUE ) ) # neg log like
#max log liklihood equivalent to minimising neg log liklihood
#easier to pass a function to minimise into optim!!!
#(although it can do maximisiation, it's just handier)
}
initial <- c(1.0,0.5)
mle <- optim( initial, fn=negll, gr=NULL, xx=x, method="BFGS" )
mle$par#very close to true values
dgamma(1,5,6)
dgamma(1,-5,6)
exp(7.12)
exp(2)
exp(7.389056)
xs<-runif(100,0,1)
xs
ys<-runif(100,0,1)
alpha<--1*(100/sum(log(xs)))
alpha<--1*(1+(100/sum(log(xs))))
beta<--1*(1+(100/sum(log(ys))))
probs<-((1+alpha)(1+beta)*(xs^alpha)*(ys^beta)
hist(probs)
hist(probs)
probs<-((1+alpha)*(1+beta)*(xs^alpha)*(ys^beta)
xs<-runif(100,0,1)
ys<-runif(100,0,1)
alpha<--1*(1+(100/sum(log(xs))))
beta<--1*(1+(100/sum(log(ys))))
probs<-((1+alpha)*(1+beta)*(xs^alpha)*(ys^beta)
hist(probs)
xs<-runif(100,0,1)
ys<-runif(100,0,1)
alpha<--1*(1+(100/sum(log(xs))))
beta<--1*(1+(100/sum(log(ys))))
probs<-((1+alpha)*(1+beta)*(xs^alpha)*(ys^beta)
xs<-runif(100,0,1)
xs<-runif(100,0,1)
ys<-runif(100,0,1)
alpha<--1*(1+(100/sum(log(xs))))
beta<--1*(1+(100/sum(log(ys))))
probs<-((1+alpha)*(1+beta)*(xs^alpha)*(ys^beta)
probs
probs<-(1+alpha)*(1+beta)*(xs^alpha)*(ys^beta)
hist(probs)
probs
#testnoise
testthat::expect_error(
noise(-200,5,250),
"frames cannot be less than 0"
)
usethis::use_testthat()
setwd("C:/Users/rosie/OneDrive - TCDUD.onmicrosoft.com/TCD/4th Year/FYP/eegdatasim/tests/testthat")
usethis::use_testthat()
use_test()
test_file()
path <- testthat_example(""C:/Users/rosie/OneDrive - TCDUD.onmicrosoft.com/TCD/4th Year/FYP/eegdatasim/tests")
test_file(path)
devtools::test()
library(eegdatasim)
?power_determination()
devtools::test()
devtools::test()
devtools::test()
my_p<-power_determination(0.1,7,5,200,250,5,5)
my_p
testthat::expect_length(power_determination(0.1,7,5,200,250,5,5),2)
devtools::test()
devtools::test()
testthat::expect_length(power_determination(0.1,7,5,200,250,5,5),2,5)
devtools::test()
type(my_p)
typeof(my_p)
devtools::test()
class(my_p)
devtools::test()
devtools::test()
